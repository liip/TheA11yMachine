#!/usr/bin/env node

'use strict';

/**
 * Copyright (c) 2016, Ivan Enderlin and Liip
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without modification,
 * are permitted provided that the following conditions are met:
 *
 * 1. Redistributions of source code must retain the above copyright notice, this
 *    list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright notice,
 *    this list of conditions and the following disclaimer in the documentation
 *    and/or other materials provided with the distribution.
 *
 * 3. Neither the name of the copyright holder nor the names of its contributors
 *    may be used to endorse or promote products derived from this software without
 *    specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 *  LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

var Logger   = require('./lib/logger');
var Tester   = require('./lib/tester');
var async    = require('async');
var process  = require('process');
var program  = require('commander');
var readline = require('readline');

// Define all the options, with their description and default value.
program
    .usage('[options] url …')
    .option(
        '-c, --filter-by-codes <codes>',
        'Filter results by comma-separated WCAG codes (e.g. `H25,H91,G18`).'
    )
    .option(
        '-C, --exclude-by-codes <codes>',
        'Exclude results by comma-separated WCAG codes (e.g. `H25,H91,G18`).'
    )
    .option(
        '-d, --maximum-depth <depth>',
        'Explore up to a maximum depth (hops).',
        3
    )
    .option(
        '-m, --maximum-urls <maximum_urls>',
        'Maximum number of URLs to compute.',
        128
    )
    .option(
        '-o, --output <output_directory>',
        'Output directory.',
        __dirname + '/a11ym_output'
    )
    .option(
        '-r, --report <report>',
        'Report format: `cli`, `csv`, `html` (default), `json` or `markdown`.',
        'html'
    )
    .option(
        '-s, --standards <standards>',
        'Standard to use: `WCAG2A`, `WCAG2AA` (default), ` WCAG2AAA`, `Section508`, `HTML` or your own (see `--sniffers`). `HTML` can be combined with any other by a comma.',
        'WCAG2AA'
    )
    .option(
        '-S, --sniffers <sniffers>',
        'Path to the sniffers file, e.g. `resource/sniffers.js` (default).',
        __dirname + '/resource/sniffers.js'
    )
    .option(
        '-u, --filter-by-urls <urls>',
        'Filter URL to test by using a regular expression without delimiters (e.g. \'news|contact\').'
    )
    .option(
        '-U, --exclude-by-urls <urls>',
        'Exclude URL to test by using a regular expression without delimiters (e.g. \'news|contact\').'
    )
    .option(
        '-w, --workers <workers>',
        'Number of workers, i.e. number of URLs computed in parallel.',
        4
    )
    .option(
        '--http-auth-user <http_auth_user>',
        'Username to authenticate all HTTP requests.'
    )
    .option(
        '--http-auth-password <http_auth_password>',
        'Password to authenticate all HTTP requests.'
    )
    .option(
        '--http-tls-disable',
        'Disable TLS/SSL when crawling or downloading pages.'
    )
    .option(
        '-V, --no-verbose',
        'Make the program silent.',
        false
    )
    .parse(process.argv);

// No URL to compute? Then exit.
if (!program.args[0]) {
    program.help();
    process.exit(1);
}

// Set the logger.
var logger = new Logger(program);

// Maximum number of URL to compute.
var maximumUrls = +program.maximumUrls;

// When an error occurs, update this flag. It will change the exit code of the
// process.
var hasErrors = false;

// When the test queue has been stopped once, update this flag. It avoids to do
// the “stop computation” more than once.
var isStopped = false;

// Force to quit the program. If errors, exit with a non 0 exit code.
function quit() {
    process.exit(true === hasErrors ? 2 : 0);
}

// Kill the test queue and stop the crawler.
function killQueue(reason) {
    if (false !== isStopped) {
        return;
    }

    isStopped = true;
    logger.write(logger.colorize.white.bgRed('Test queue is stopping. ' + reason) + '\n');

    if(undefined !== crawler) {
        crawler.stop();
    }

    testQueue.kill();
    logger.write(logger.colorize.white.bgRed(testQueue.running() + ' tests are still running, waiting…') + '\n');
}

var tester = Tester(program);

// Queue of URL waiting to be tested. This queue has a user-defined concurrency
// level. When a test is executed, it calls the “complete” callback on the
// task. When the maximum number of URL is reached, then we kill this queue.
var testQueue = async.queue(
    function (url, onTaskComplete) {
        if (--maximumUrls < 0) {
            onTaskComplete();
            killQueue('Maximum URLs reached.');

            return;
        }

        var _wrap = function (callback) {
            return function () {
                callback();

                if (0 === testQueue.running()) {
                    quit();
                }
            };
        };

        logger.write(
            logger.colorize.black.bgGreen(' ' + (program.maximumUrls - maximumUrls) + '/' + program.maximumUrls + ' ') +
            ' ' +
            logger.colorize.black.bgGreen('Run: ' + url + '.') +
            '\n'
        );
        tester(
            url,
            _wrap(
                function (results) {
                    onTaskComplete(null, results);
                }
            ),
            _wrap(
                function (error) {
                    hasErrors = true;
                    onTaskComplete(error);
                }
            )
        );
    },
    program.workers
);

if ((1 === program.args.length && '-' === program.args[0]) || 1 < program.args.length) {
    maximumUrls = 0;

    var add = function (url) {
        ++maximumUrls;
        testQueue.push(url);
    };

    if('-' === program.args[0]) {
        readline
            .createInterface(process.stdin, undefined)
            .on('line', add)
            .on('close', function() { program.maximumUrls = maximumUrls; });
    } else {
        program.args.forEach(add);
        program.maximumUrls = maximumUrls;
    }
} else if (1 === maximumUrls) {
    testQueue.push(program.args[0]);
} else {
    var Crawler = require('./lib/crawler');
    var crawler = new Crawler(program);

    crawler.add(program.args[0]);
    crawler.start(testQueue);
}

process.on(
    'SIGINT',
    new function () {
        var firstSignal = true;

        return function () {
            killQueue('SIGINT');

            if (false === firstSignal) {
                logger.write(logger.colorize.white.bgRed('Yes master!') + '\n');

                process.exit(255);
            }

            firstSignal = false;
        }
    }
);
